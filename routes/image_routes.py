import os, torch
from enum import Enum
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException, Query
from fastapi.responses import FileResponse
from PIL import Image
from torchvision import transforms
import torch.nn.functional as F

from utils.exceptions import InvalidFileException, ModelNotLoadedException
from utils.auth import get_current_user
from utils.image import validate_image
from config.settings import UPLOAD_DIR, RESULT_DIR

from network.colorization_model import ColorizationModel
from network.colorization_model_unet import ColorizationUNetModel
from network.models import uformer

# ============================================================
# ê³µí†µ ìœ í‹¸
# ============================================================

def pad_to_divisible(x, div=16):
    _, _, h, w = x.size()
    pad_h = (div - h % div) % div
    pad_w = (div - w % div) % div
    return F.pad(x, (0, pad_w, 0, pad_h)), h, w

class ProcessingMode(str, Enum):
    COLORIZE = "colorize"
    RESTORE = "restore"

router = APIRouter()

# ============================================================
# âœ… ì „ì—­ ëª¨ë¸ ìºì‹± (ë¡œë“œ 1íšŒë§Œ ìˆ˜í–‰)
# ============================================================
print("[INFO] Initializing colorization models...")

try:
    UNET_MODEL = ColorizationUNetModel()
    ECCV16_MODEL = ColorizationModel()
    print("[INFO] âœ… Colorization models successfully loaded and cached.")
except Exception as e:
    print(f"[ERROR] âŒ Failed to initialize models: {e}")
    UNET_MODEL, ECCV16_MODEL = None, None

MODEL_DISPATCH = {
    "unet": lambda img: UNET_MODEL.colorize_with_unet(img) if UNET_MODEL else (_ for _ in ()).throw(ModelNotLoadedException("UNet ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")),
    "eccv16": lambda img: ECCV16_MODEL.colorize_with_eccv16(img) if ECCV16_MODEL else (_ for _ in ()).throw(ModelNotLoadedException("ECCV16 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")),
}

# ============================================================
# ğŸ¨ /colorize : í‘ë°± â†’ ì»¬ëŸ¬ ë³µì›
# ============================================================
@router.post("/colorize")
async def colorize(
    file: UploadFile = File(...),
    model: str = Query("eccv16", enum=["unet", "eccv16"], description="ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ"),
):
    """í‘ë°± ì´ë¯¸ì§€ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜ (UNet / ECCV16 ì„ íƒ ê°€ëŠ¥)"""
    validate_image(file)
    mode = ProcessingMode.COLORIZE
    user_id = "temp"

    safe_filename = f"{user_id}_{file.filename}"
    input_path = os.path.join(UPLOAD_DIR, safe_filename)
    output_filename = f"{mode}d_{safe_filename}"
    output_path = os.path.join(RESULT_DIR, output_filename)

    try:
        # 1ï¸âƒ£ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥
        content = await file.read()
        with open(input_path, "wb") as f:
            f.write(content)

        # 2ï¸âƒ£ PIL ë¡œë“œ
        pil_data = Image.open(input_path).convert("RGB")

        # 3ï¸âƒ£ ì„ íƒí•œ ëª¨ë¸ í˜¸ì¶œ
        if model.lower() not in MODEL_DISPATCH:
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model}")

        print(f"[DEBUG] ëª¨ë¸ í˜¸ì¶œ ì‹œì‘: {model.lower()}, ì…ë ¥ ì´ë¯¸ì§€ size: {pil_data.size}, mode: {pil_data.mode}")

        # =========================
        # ëª¨ë¸ë³„ ë…ë¦½ _process_image í˜¸ì¶œ
        # =========================
        if model.lower() == "unet":
            out_img = UNET_MODEL._process_image(pil_data)  # UNet ì „ìš© ì²˜ë¦¬
        elif model.lower() == "eccv16":
            out_img = ECCV16_MODEL._process_image(pil_data)  # ECCV16 ì „ìš© ì²˜ë¦¬

        print(f"[DEBUG] ëª¨ë¸ í˜¸ì¶œ ì™„ë£Œ: {model.lower()}, ì¶œë ¥ íƒ€ì…: {type(out_img)}, size: {out_img.size}")

        # 4ï¸âƒ£ ê²°ê³¼ ì €ì¥
        out_img.save(output_path)

        return FileResponse(
            output_path,
            media_type="image/png",
            filename=f"colorized_{file.filename}"
        )

    except ValueError:
        raise ModelNotLoadedException()
    except Exception as e:
        import traceback
        print(f"[ERROR] {model} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # Cleanup ì—…ë¡œë“œ íŒŒì¼
        if os.path.exists(input_path):
            os.remove(input_path)
            

@router.post("/restore")
async def restore(
    file: UploadFile = File(...),
    # current_user: dict = Depends(get_current_user)
):
    """í›¼ì†ëœ ì´ë¯¸ì§€ ë³µì›"""
    """í‘ë°± ì´ë¯¸ì§€ë¥¼ ì»¬ëŸ¬ë¡œ ë³€í™˜"""
    validate_image(file)
    mode = ProcessingMode.COLORIZE
    # user_id = current_user["user_id"]
    user_id = "temp"
    safe_filename = f"{user_id}_{file.filename}"
    input_path = os.path.join(UPLOAD_DIR, safe_filename)
    output_filename = f"{mode}d_{safe_filename}"
    output_path = os.path.join(RESULT_DIR, output_filename)
    # Save uploaded file
    try:
        content = await file.read()
        with open(input_path, "wb") as f:
            f.write(content)
        restoration_model = uformer.UNet(dim = 32)
        weight_file_path = "network/weights/damageRestoration/Uformer_B.pth"
        
        checkpoint = torch.load(weight_file_path, map_location="cpu")

        # checkpointê°€ dict êµ¬ì¡°ì¸ì§€ í™•ì¸
        if "state_dict" in checkpoint:
            checkpoint = checkpoint["state_dict"]

        model_dict = restoration_model.state_dict()
        # ë§ëŠ” í‚¤ë§Œ ì—…ë°ì´íŠ¸
        pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.size() == model_dict[k].size()}
        model_dict.update(pretrained_dict)
        restoration_model.load_state_dict(model_dict)
        restoration_model.eval()

        restoration_weights = torch.load(weight_file_path,map_location="cpu")
        restoration_model.load_state_dict(restoration_weights)
        restoration_model.eval()
        # todo - > RESIZE ë° ëª¨ë¸ë¡œë“œ ë¶€ë¶„ ë¶„ë¦¬
        transform = transforms.ToTensor()
        to_pil = transforms.ToPILImage()
        img = Image.open(input_path).convert("RGB")
        orig_w, orig_h = img.size

        img_tensor = transform(img).unsqueeze(0)
        padded_tensor, orig_h, orig_w = pad_to_divisible(img_tensor, div=16)
        with torch.no_grad():
            output_tensor = restoration_model(padded_tensor)

        # crop ì›ë˜ í¬ê¸°ë¡œ
        output_tensor = output_tensor[:, :, :orig_h, :orig_w]

        # ====== í›„ì²˜ë¦¬ ë° ì €ì¥ ======
        output_img = output_tensor.squeeze(0).cpu()
        output_img = to_pil(output_img.clamp(0, 1))
        output_img.save(output_path)

        return FileResponse(
            output_path,
            media_type="image/png",
            filename=f"restored_{file.filename}"
        )

    except ValueError as e:
        raise ModelNotLoadedException()
    except Exception as e:
        print(e)
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # Cleanup uploaded file
        if os.path.exists(input_path):
            os.remove(input_path)
            